{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_batch = \"nsample_1107\"\n",
    "sample_dir = \"CHIMES_0.6/Out/{}/{}_csv\".format(sample_batch,sample_batch)\n",
    "\n",
    "def get_vecs(df,N):\n",
    "    \n",
    "    x = []\n",
    "    y = []\n",
    "    \n",
    "    nget = int(len(df)/N)\n",
    "    cols = df.columns[4:-21]\n",
    "    nspec = len(cols)\n",
    "    select_times = df[\"t(Myrs)\"].unique()[::nget]\n",
    "    for t in select_times:\n",
    "        xx = np.zeros(nspec)\n",
    "        yy = np.zeros(2*nspec)\n",
    "        grph =df[np.logical_and(df[\"t(Myrs)\"]==t,df[\"datatype\"]==\"graph\")][cols].iloc[0]\n",
    "        drv =  df[np.logical_and(df[\"t(Myrs)\"]==t,df[\"datatype\"]==\"deriv\")][cols].iloc[0]\n",
    "        \n",
    "        xx[:] = grph.values[:]\n",
    "        yy[:nspec] = grph.values[:]\n",
    "        yy[nspec:] = drv.values[:]\n",
    "        \n",
    "        x.append(xx)\n",
    "        y.append(yy)\n",
    "    return list(cols),select_times,x,y\n",
    "    \n",
    "\n",
    "def create_dataset(dirpath,N_per_model,test_size=0.3,val_size=0.3):\n",
    "\n",
    "    X = []\n",
    "    Y = []\n",
    "    \n",
    "    dirfiles = os.listdir(dirpath)\n",
    "    total_s =  len(dirfiles)*N_per_model\n",
    "    \n",
    "    print(\"{} lines for each of the {} models = {} samples\".format(N_per_model,len(dirfiles),total_s))\n",
    "    print(\"  {} samples for training\".format(int(total_s*(1-test_size)*(1-val_size))))\n",
    "    print(\"  {} samples for validating\".format(int(total_s*(1-test_size)*val_size)))\n",
    "    print(\"  {} samples for testing\".format(int(total_s*test_size)))\n",
    "    for i in range(len(dirfiles)):\n",
    "        filename = dirfiles[i]\n",
    "        if  filename.endswith(\".csv.gz\"):\n",
    "            \n",
    "            s = \"extracting {0} ... \".format(filename)\n",
    "            if i == len(dirfiles)-1:\n",
    "                s+='\\n'        \n",
    "            if i>0:\n",
    "                s = '\\r'+s\n",
    "            print(s, end='')\n",
    "\n",
    "            filepath = os.path.join(dirpath, filename)\n",
    "            data = pd.read_csv(filepath,compression=\"gzip\")\n",
    "            cols_,sel_t,x,y = get_vecs(data,N_per_model)\n",
    "            for i in range(len(x)):\n",
    "                X.append(x[i])\n",
    "                Y.append(y[i])\n",
    "    \n",
    "            \n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    print(\"Extraction completed. Splitting dataset...\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=test_size)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train,y_train,test_size=val_size)\n",
    "    print (\"Done.\")\n",
    "    return {\"cols\":cols_,\"times\":sel_t,\"x_train\":X_train,\"x_val\":X_val,\"x_test\":X_test,\"y_train\":y_train,\"y_val\":y_val,\"y_test\":y_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 lines for each of the 150 models = 1500 samples\n",
      "  735 samples for training\n",
      "  315 samples for validating\n",
      "  450 samples for testing\n",
      "extracting nsample_1107_99.csv.gz ...  \n",
      "Extraction completed. Splitting dataset...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "dataset = create_dataset(sample_dir,10,0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_specs = len(dataset[\"cols\"])\n",
    "num_epochs = 10\n",
    "batch_size = 128\n",
    "learning_rate = 1e-3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-113-fcf629dbc253>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m optimizer = torch.optim.Adam(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mcuda\u001b[1;34m(self, device)\u001b[0m\n\u001b[0;32m    678\u001b[0m             \u001b[0mModule\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m         \"\"\"\n\u001b[1;32m--> 680\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mxpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    568\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 570\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    571\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    568\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 570\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    571\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    591\u001b[0m             \u001b[1;31m# `with torch.no_grad():`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m                 \u001b[0mparam_applied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    594\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    678\u001b[0m             \u001b[0mModule\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m         \"\"\"\n\u001b[1;32m--> 680\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mxpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    206\u001b[0m                 \"multiprocessing, you must use the 'spawn' start method\")\n\u001b[0;32m    207\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_cuda_getDeviceCount'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             raise AssertionError(\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "#img_transform = transforms.Compose([\n",
    "#    transforms.ToTensor(),\n",
    "#    transforms.Normalize([0.5], [0.5])\n",
    "#])\n",
    "\n",
    "#dataset = MNIST('./data', transform=img_transform)\n",
    "#dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "class autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(num_specs, 32),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(True), \n",
    "            nn.Linear(16, 8), \n",
    "            nn.ReLU(True), \n",
    "            nn.Linear(8, 5))\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(5, 8),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(8, 16),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(16, 32),\n",
    "            nn.ReLU(True), nn.Linear(32, 2*num_specs), nn.Tanh())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = autoencoder()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for data in dataloader:\n",
    "        img, _ = data\n",
    "        img = img.view(img.size(0), -1)\n",
    "        img = Variable(img).cuda()\n",
    "        # ===================forward=====================\n",
    "        output = model(img)\n",
    "        loss = criterion(output, img)\n",
    "        # ===================backward====================\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # ===================log========================\n",
    "    print('epoch [{}/{}], loss:{:.4f}'\n",
    "          .format(epoch + 1, num_epochs, loss.data[0]))\n",
    "    if epoch % 10 == 0:\n",
    "        pic = to_img(output.cpu().data)\n",
    "        save_image(pic, './mlp_img/image_{}.png'.format(epoch))\n",
    "\n",
    "torch.save(model.state_dict(), './sim_autoencoder.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(\"dataset\",dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<#--------------------------------------------------------------------------------------------------->0\n",
      "\r",
      "<##-------------------------------------------------------------------------------------------------->1\n",
      "\r",
      "<###------------------------------------------------------------------------------------------------->2\n",
      "\r",
      "<####------------------------------------------------------------------------------------------------>3\n",
      "\r",
      "<#####----------------------------------------------------------------------------------------------->4\n",
      "\r",
      "<######---------------------------------------------------------------------------------------------->5\n",
      "\r",
      "<#######--------------------------------------------------------------------------------------------->6\n",
      "\r",
      "<########-------------------------------------------------------------------------------------------->7\n",
      "\r",
      "<#########------------------------------------------------------------------------------------------->8\n",
      "\r",
      "<##########------------------------------------------------------------------------------------------>9\n",
      "\r",
      "<###########----------------------------------------------------------------------------------------->10\n",
      "\r",
      "<############---------------------------------------------------------------------------------------->11\n",
      "\r",
      "<#############--------------------------------------------------------------------------------------->12\n",
      "\r",
      "<##############-------------------------------------------------------------------------------------->13\n",
      "\r",
      "<###############------------------------------------------------------------------------------------->14\n",
      "\r",
      "<################------------------------------------------------------------------------------------>15\n",
      "\r",
      "<#################----------------------------------------------------------------------------------->16\n",
      "\r",
      "<##################---------------------------------------------------------------------------------->17\n",
      "\r",
      "<###################--------------------------------------------------------------------------------->18\n",
      "\r",
      "<####################-------------------------------------------------------------------------------->19\n",
      "\r",
      "<#####################------------------------------------------------------------------------------->20\n",
      "\r",
      "<######################------------------------------------------------------------------------------>21\n",
      "\r",
      "<#######################----------------------------------------------------------------------------->22\n",
      "\r",
      "<########################---------------------------------------------------------------------------->23\n",
      "\r",
      "<#########################--------------------------------------------------------------------------->24\n",
      "\r",
      "<##########################-------------------------------------------------------------------------->25\n",
      "\r",
      "<###########################------------------------------------------------------------------------->26\n",
      "\r",
      "<############################------------------------------------------------------------------------>27\n",
      "\r",
      "<#############################----------------------------------------------------------------------->28\n",
      "\r",
      "<##############################---------------------------------------------------------------------->29\n",
      "\r",
      "<###############################--------------------------------------------------------------------->30\n",
      "\r",
      "<################################-------------------------------------------------------------------->31\n",
      "\r",
      "<#################################------------------------------------------------------------------->32\n",
      "\r",
      "<##################################------------------------------------------------------------------>33\n",
      "\r",
      "<###################################----------------------------------------------------------------->34\n",
      "\r",
      "<####################################---------------------------------------------------------------->35\n",
      "\r",
      "<#####################################--------------------------------------------------------------->36\n",
      "\r",
      "<######################################-------------------------------------------------------------->37\n",
      "\r",
      "<#######################################------------------------------------------------------------->38\n",
      "\r",
      "<########################################------------------------------------------------------------>39\n",
      "\r",
      "<#########################################----------------------------------------------------------->40\n",
      "\r",
      "<##########################################---------------------------------------------------------->41\n",
      "\r",
      "<###########################################--------------------------------------------------------->42\n",
      "\r",
      "<############################################-------------------------------------------------------->43\n",
      "\r",
      "<#############################################------------------------------------------------------->44\n",
      "\r",
      "<##############################################------------------------------------------------------>45\n",
      "\r",
      "<###############################################----------------------------------------------------->46\n",
      "\r",
      "<################################################---------------------------------------------------->47\n",
      "\r",
      "<#################################################--------------------------------------------------->48\n",
      "\r",
      "<##################################################-------------------------------------------------->49\n",
      "\r",
      "<###################################################------------------------------------------------->50\n",
      "\r",
      "<####################################################------------------------------------------------>51\n",
      "\r",
      "<#####################################################----------------------------------------------->52\n",
      "\r",
      "<######################################################---------------------------------------------->53\n",
      "\r",
      "<#######################################################--------------------------------------------->54\n",
      "\r",
      "<########################################################-------------------------------------------->55\n",
      "\r",
      "<#########################################################------------------------------------------->56\n",
      "\r",
      "<##########################################################------------------------------------------>57\n",
      "\r",
      "<###########################################################----------------------------------------->58\n",
      "\r",
      "<############################################################---------------------------------------->59\n",
      "\r",
      "<#############################################################--------------------------------------->60\n",
      "\r",
      "<##############################################################-------------------------------------->61\n",
      "\r",
      "<###############################################################------------------------------------->62\n",
      "\r",
      "<################################################################------------------------------------>63\n",
      "\r",
      "<#################################################################----------------------------------->64\n",
      "\r",
      "<##################################################################---------------------------------->65\n",
      "\r",
      "<###################################################################--------------------------------->66\n",
      "\r",
      "<####################################################################-------------------------------->67\n",
      "\r",
      "<#####################################################################------------------------------->68\n",
      "\r",
      "<######################################################################------------------------------>69\n",
      "\r",
      "<#######################################################################----------------------------->70\n",
      "\r",
      "<########################################################################---------------------------->71\n",
      "\r",
      "<#########################################################################--------------------------->72\n",
      "\r",
      "<##########################################################################-------------------------->73\n",
      "\r",
      "<###########################################################################------------------------->74\n",
      "\r",
      "<############################################################################------------------------>75\n",
      "\r",
      "<#############################################################################----------------------->76\n",
      "\r",
      "<##############################################################################---------------------->77\n",
      "\r",
      "<###############################################################################--------------------->78\n",
      "\r",
      "<################################################################################-------------------->79\n",
      "\r",
      "<#################################################################################------------------->80\n",
      "\r",
      "<##################################################################################------------------>81\n",
      "\r",
      "<###################################################################################----------------->82\n",
      "\r",
      "<####################################################################################---------------->83\n",
      "\r",
      "<#####################################################################################--------------->84\n",
      "\r",
      "<######################################################################################-------------->85\n",
      "\r",
      "<#######################################################################################------------->86\n",
      "\r",
      "<########################################################################################------------>87\n",
      "\r",
      "<#########################################################################################----------->88\n",
      "\r",
      "<##########################################################################################---------->89\n",
      "\r",
      "<###########################################################################################--------->90\n",
      "\r",
      "<############################################################################################-------->91\n",
      "\r",
      "<#############################################################################################------->92\n",
      "\r",
      "<##############################################################################################------>93\n",
      "\r",
      "<###############################################################################################----->94\n",
      "\r",
      "<################################################################################################---->95\n",
      "\r",
      "<#################################################################################################--->96\n",
      "\r",
      "<##################################################################################################-->97\n",
      "\r",
      "<###################################################################################################->98\n",
      "\r",
      "<####################################################################################################>\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# status generator\n",
    "def range_with_status(total):\n",
    "    \"\"\" iterate from 0 to total and show progress in console \"\"\"\n",
    "    n=0\n",
    "    while n<total:\n",
    "        done = '#'*(n+1)\n",
    "        todo = '-'*(total-n-1)\n",
    "        s = '<{0}>'.format(done+todo)\n",
    "        if not todo:\n",
    "            s+='\\n'        \n",
    "        if n>0:\n",
    "            s = '\\r'+s\n",
    "        print(s, end='')\n",
    "        yield n\n",
    "        n+=1\n",
    "\n",
    "# example for use of status generator\n",
    "for i in range_with_status(100):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
